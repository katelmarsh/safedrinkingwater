
---
title: "Water Quality"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Data from NOAA about storm events from 1951-today 
frustrating that they do not have an API, why is it a CSV download of like 35 files 
Link: https://www.ncdc.noaa.gov/stormevents/listevents.jsp?eventType=%28Z%29+Winter+Storm&beginDate_mm=01&beginDate_dd=01&beginDate_yyyy=2000&endDate_mm=12&endDate_dd=31&endDate_yyyy=2021&county=ALL&hailfilter=0.00&tornfilter=0&windfilter=000&sort=DT&submitbutton=Search&statefips=48%2CTEXAS 

this is preliminary work before I combined and pared down the bulk data. 
```{r}
hurricanes <- read.csv("~/Downloads/storm_data_tx_hurricane.csv")
trop_storm <- read.csv("~/Downloads/storm_data_tropstrom_tropdepres.csv")
coastal <- read.csv("~/Downloads/storm_data_coastal_flood.csv")

colnames(hurricanes) == colnames(trop_storm)

extreme_weather <- rbind(hurricanes, trop_storm)

lapply(extreme_weather, class)
summary(extreme_weather$INJURIES_INDIRECT)
extreme_weather[which(extreme_weather$INJURIES_INDIRECT == 2400),] # max is hurricane Ike (which I was in Houston for)

```


## NOAA data part 2 
now I'm trying to just use the bulk data then pare down from there because the website is so annoying and they only give 500 searched results at a time or bulk downloads 
```{r}
library(data.table)
library(dplyr)
library(tidyr)
library(purrr)

dt = fread("~/Downloads/StormEvents_details-ftp_v1.0_d1950_c20170120.csv.gz")

files <- dir("~/Downloads/storm_events", pattern = "*.csv.gz")

data <- paste0("~/Downloads/storm_events/", files) %>%
  map(fread)
unique(lapply(data, length)) # length of 51 and 11 


#made function to find length of a element in a list
lengthIs <- function(n) function(x) length(x)==n

# storm details
data_51 <- do.call(rbind, Filter(lengthIs(51), data))

data_fat <-  data[72:139] # manually removed the years / csvs with no data 
# fatality data 
data_fat <- do.call(rbind, Filter(lengthIs(11), data_fat))

data_loc <-  data[188:214]                 
# location data 
data_loc <- rbindlist(data_loc, fill=TRUE)

data_51 <- data_51[data_51$STATE == "TEXAS"] # weather details for just texas 
most_dat <- merge(data_51, data_fat, by = "EVENT_ID", all.x = TRUE) # weather and fatalities for texas 
tx_weather <- merge(most_dat, data_loc, by = "EVENT_ID", all.x = TRUE) # final dataset

write.csv(tx_weather, "~/Downloads/tx_weather_noaa.csv")

```

#Exploring the TX Weather Data 

```{r}
tx_weather <- fread("~/Downloads/tx_weather_noaa.csv")

#Paulina's code for filtering and cleaning property damage $ 
tx_weather=tx_weather %>% filter(EVENT_TYPE%in%events) %>% mutate(Z_FIPS=case_when(
  CZ_FIPS<100&CZ_FIPS>9~paste0(0,CZ_FIPS),
  CZ_FIPS<10~paste0("00",CZ_FIPS),
  CZ_FIPS>99~paste0(CZ_FIPS))) %>% 
  mutate(Z_FIPS=paste0(STATE_FIPS,Z_FIPS), DAMAGE_PROPERTY_NUM= as.numeric(gsub("[a-zA-Z ]", "", DAMAGE_PROPERTY)),
         Q=str_sub(DAMAGE_PROPERTY,-1,-1)) %>% 
  mutate(DAMAGE_PROPERTY_NUM=case_when( #Getting numeric values for property damage
    Q=="K"~DAMAGE_PROPERTY_NUM*1000,
    Q=="M"~DAMAGE_PROPERTY_NUM*1000000,
    Q=="B"~DAMAGE_PROPERTY_NUM*1000000000,
    Q==0~DAMAGE_PROPERTY_NUM
    ))
#The Zone FIPS do not correspond to county FIPS. Texas has only 254 counties 

classes <- lapply(tx_weather, class)
numeric <- which(classes == "numeric")

out <- lm(MAGNITUDE ~ BEGIN_DAY + BEGIN_TIME + END_DAY + END_TIME + YEAR + BEGIN_LAT + BEGIN_LON + END_LAT + END_LON + INJURIES_DIRECT + DEATHS_DIRECT + DEATHS_INDIRECT + INJURIES_INDIRECT, data=tx_weather)
summary(out)
plot(out)

# checking to see the counties listed for the weather events -- there are 276 unique 
length(unique(tx_weather$CZ_NAME[which(tx_weather$CZ_TYPE == 'C')]))

hist(tx_weather$YEAR)

plot(tx_weather$YEAR, tx_weather$DAMAGE_PROPERTY_NUM)

counts <- table(tx_weather$MONTH_NAME)
barplot(counts, main="Event Month",las=2, cex.names=.75)

counts <- table(tx_weather$BEGIN_TIME)
barplot(counts, main="Event Beginning Time",las=2, cex.names=.75)

counts <- table(tx_weather$EVENT_TYPE)
barplot(counts, main="Event Type",las=2, cex.names=.5)

```
Interesting regression here. When using magnitude as the indicator variable, we find a significant relationship between it and beginning lat/long, ending lat/long, and year. We don't find any relationship between that and injuries/deaths or beginning day/time or ending day/time. However, it is probably a bad indicator variable because there at 57,000 NA variables in the magnitude column. Magnitude refers to only wind speed and hail size. 

## SDWIS Federal Reports on Texas PWS 
Link: https://ofmpub.epa.gov/apex/sfdw/f?p=108:21::::RP,RIR::

```{r}
sdwis <- read.csv("~/Downloads/water_system_summary_SDWIS_FED_Reports.csv")

lapply(sdwis, class)

# cleaning! removing commas from population count and making numeric
y <- c(sdwis$Population.Served.Count)
sdwis$Population.Served.Count = as.numeric(gsub(",", "", y))
summary(sdwis$Population.Served.Count)

# violations 
hist(sdwis$X..of.Violations)
summary(sdwis$X..of.Violations) 
# one of them has 2411?! but it looks like most are under 10 
sort(table(sdwis$Counties.Served[which(sdwis$X..of.Violations > 22)])) # seeing if the top quartile of violations are concentrated in certain counties -- it appears that Harris county (Houston), Brazoria, Montgomery, and Lubbock are the top offenders of counties with lots of water systems in the top quartile -- this should probably be indexed for amount of PWS in each county, but it is interesting that Harris county has such a larger amt than Dallas 

plot(sdwis$X..of.Violations, sdwis$Population.Served.Count, main = "Violations vs Population Served")


```


```{r}
reg <- lm(X..of.Violations ~ Population.Served.Count + X..of.Site.Visits + X..of.Facilities, data=sdwis)
summary(reg)
# find significant relationship between violation count and site visit count
plot(sdwis$X..of.Site.Visits, sdwis$X..of.Violations)


reg <- lm(Population.Served.Count ~  X..of.Violations + X..of.Site.Visits + X..of.Facilities, data=sdwis)
summary(reg)
# find a significant relationship between population served and site visits or facilities 
plot(sdwis$Population.Served.Count, sdwis$X..of.Facilities, main = "population served vs number of facilities")
plot(sdwis$X..of.Site.Visits, sdwis$Population.Served.Count, main = "number of site visits vs population served")
reg <- lm(X..of.Site.Visits ~  X..of.Violations + Population.Served.Count + X..of.Facilities, data=sdwis)
summary(reg)
plot(reg)
```
We find significant relationship between violation count and site visit count. We also find a a significant relationship between population served and site visits or facilities. These relationships follow common sense. PWSs with large amounts of violations probably have more visits. Similarly, PWSs that serve a larger population probably have more facilties and site visits. 

```{r}
weather_counties <- tx_weather$CZ_NAME[which(tx_weather$CZ_TYPE == 'C')] # names of counties in the tx_weather set
length(unique(weather_counties)) # checking for how many county names there are. there are 276 whcih is much above the amt of 254. since I need cleaning for both this dataset and the other one, I'm going to get a set of county names to double check. 
county_list <- read.csv("~/Downloads/tx_counties.csv") # double checking CSV

'%!in%' <- function(x,y)!('%in%'(x,y)) # lil function to make it easier

wrong_counties <- unique(weather_counties[toupper(weather_counties) %!in% toupper(county_list$County.Name)]) # list of counties that are not in the standard list, need cleaning

## SDWIS Counties 
# Counties
unique(sdwis$EPA.Region) # they're all in region 6 which is Texas 

length(unique(sdwis$Counties.Served)) # only 256, 2 extra counties 
wrong_counties_2 <-  unique(sdwis$Counties.Served[toupper(sdwis$Counties.Served) %!in% toupper(county_list$County.Name)])  # list of counties that are not in the standard list, need cleaning 
# after looking at this looks like "Dallas, Johnson" and "Coke, Concho, Ector, Howard, Martin, Scurry, Ward" are the extra counties 

```
Trying to figure out how to combine given that multiple PWSs service one county and different parts of one county. 
https://www.dshs.texas.gov/chs/info/info_txco.shtm -- decided to grab a CSV of official county names and FIPS codes from the Texas Government, this one is from the Department of State Health Services. 


```{r}
library(ggplot2)

filt_weather <- tx_weather[tx_weather$EVENT_TYPE == c("Flash Flood","Hurricane","Coastal Flood", "Flood", "Storm Surge/Tide", "Heavy Rain", "Hurricane (Typhoon)", "Tropical Storm", "Tropical Depression", "THUNDERSTORM WINDS/ FLOOD", "Drought")]


qplot(BEGIN_LON, BEGIN_LAT, data=filt_weather, colour=EVENT_TYPE, 
      main = "Map of Event Beginning Locations in Texas")
qplot(END_LON, END_LAT, data=filt_weather, colour=EVENT_TYPE, 
      main = "Map of Event Ending Locations in Texas")

#+ 
#      borders("county") + scale_size_area()

table(filt_weather$EVENT_TYPE[which(is.na(filt_weather$BEGIN_LAT | filt_weather$BEGIN_LON))])
# missing NA values for mostly flash floods and floods

table(filt_weather$EVENT_TYPE[which(is.na(filt_weather$LATITUDE | filt_weather$LONGITUDE))])
# missing more for flash floods and floods, mostly the same missing location data 

table(filt_weather$EVENT_TYPE[which(is.na(filt_weather$BEGIN_LAT | filt_weather$BEGIN_LON))])

```
##Trying out a spatial join 
using the urbnmapr r package to join and grab the counties/FIPS etc 

```{r}
install.packages("devtools")
library(tidyverse)
library(urbnmapr)
library(devtools)
library(ggplot2)

devtools::install_github("UrbanInstitute/urbnmapr")

ggplot() + 
  geom_polygon(data = urbnmapr::states, mapping = aes(x = long, y = lat, group = group),
		           fill = "grey", color = "white") +
  coord_map(projection = "albers", lat0 = 39, lat1 = 45)

tx_weather$CZ_FIPS = as.character(tx_weather$CZ_FIPS)
class(counties$county_fips)

dim(tx_weather)


counties_tx = counties[counties$state_name == "Texas",]
tx_weather$BEGIN_LAT_R <- round(tx_weather$BEGIN_LAT,1) 
tx_weather$BEGIN_LON_R <- round(tx_weather$BEGIN_LON,1) 

#joining by long/lat just to see (this doesn't really work)
#joined_weather <- left_join(tx_weather, counties_tx, by= c("BEGIN_LON_R" = "long", "BEGIN_LAT_R" = "lat"))

#joined by FIPS code
joined_weather <- left_join(tx_weather, counties_tx, by= c("CZ_FIPS" = "county_fips"))
dim(joined_weather)
joined_weather <- joined_weather[!is.na(joined_weather$BEGIN_LAT),] 

joined_weather %>%
  ggplot(aes(BEGIN_LON, BEGIN_LAT,group = group, if(!all(is.na(DAMAGE_PROPERTY))){fill=DAMAGE_PROPERTY})) +
  geom_polygon(color = NA) +
  coord_map(projection = "albers", lat0 = 39, lat1 = 45) +
  labs(fill = "Property Damage")

# texas_weather code 
joined_weather %>% 
  ggplot(mapping = aes(BEGIN_LON, BEGIN_LAT, group = group, fill = DAMAGE_PROPERTY_NUM)) +
  geom_polygon(color = "#ffffff", size = .25) +
  scale_fill_gradientn(labels = scales::percent,colors=NA,
                       guide = guide_colorbar(title.position = "top")) +
  coord_map(projection = "albers", lat0 = 39, lat1 = 45) +
  theme(legend.title = element_text(),
        legend.key.width = unit(.5, "in")) +
  labs(fill = "Property Damage")


```

#trying again with SF and usaboundaries 
tutorial: https://ryanpeek.org/2019-04-29-spatial-joins-in-R/

```{r}
library(sf)
library(USAboundaries)
devtools::install_github("ropensci/USAboundariesData")
library(USAboundariesData)
library(ggplot2)
library(scales)

us <- us_boundaries(type="state", resolution = "low") %>% 
  filter(!state_abbr %in% c("PR", "AK", "HI"))

tx <- USAboundaries::us_states(resolution = "high", states = "TX")

# make a box around texas (a grid with an n=1) for inset
tx_box <- st_make_grid(tx, n = 1)

# get texas county boundary
tx_co <- USAboundaries::us_counties(resolution = "high", states = "TX")

# make sure we have all the pieces with a quick test plot
plot(tx$geometry, col="gray50", border="maroon")
plot(tx_co$geometry, add=T, border="pink", col=NA)
plot(tx_box, add=T, border="red3", col=NA, lwd=2)

#have to filter out misisng values to make it work 
filt_tx_weather <- tx_weather[!is.na(tx_weather$BEGIN_LAT),] 

# make spatial
filt_tx_weather <- as.data.frame(filt_tx_weather) %>% 
  st_as_sf(coords=c("BEGIN_LON","BEGIN_LAT"), crs=4326, remove=FALSE)  

plot(filt_tx_weather$geometry, cex=0.5)
plot(tx$geometry, col=alpha("gray", 0.5), border="#440154FF", lwd=1.5, add=TRUE)
plot(filt_tx_weather$geometry, add=T, pch=21, bg="#21908CFF", cex=0.7, col="black")
title("NOAA Texas Extreme Weather Events Beginning Locations")

```



# Some Links I've been using 
https://www.maths.lancs.ac.uk/~rowlings/Teaching/UseR2012/cheatsheet.html


```{r}
library(sp)
library(rgdal)
library(rgeos)
library(raster)
library(plyr)
library(dplyr)
library(maps)
library(mapdata)
library(maptools)

cords <- cbind(filt_tx_weather$BEGIN_LON, filt_tx_weather$BEGIN_LAT)
sp_cords <- SpatialPoints(cords) # makes them spatial 
plot(sp_cords) # plot! 
summary(sp_cords) # summarizes cords 
coordinates(sp_cords) # prints cords

crs.geo <-CRS("+init=EPSG:32633")
proj4string(sp_cords) <- crs.geo  # define projection system of our data
is.projected(sp_cords)
summary(sp_cords)
st_crs(filt_tx_weather) <- 4326 # hard coding the CRS compatibility 
filt_tx_weather <- st_transform(filt_tx_weather, 4326)  # hard coding the CRS compatibility 

#merge sp cords back into tx_weather 
sp_tx_df <- SpatialPointsDataFrame(sp_cords, as.data.frame(filt_tx_weather))
summary(sp_tx_df)

#merged_weather <- join(tx_weather, counties_tx, by.x = "CZ_FIPS", by.y ="county_fips")
cords <- cbind(counties_tx$long, counties_tx$lat)
sp_cords <- SpatialPoints(cords) # makes them spatial
crs.geo <-CRS("+init=EPSG:32633")
proj4string(sp_cords) <- crs.geo  # define projection system of our data
is.projected(sp_cords)
summary(sp_cords)
sp_tx_counties <- SpatialPointsDataFrame(sp_cords, as.data.frame(counties_tx))
sf_counties <- st_as_sf(sp_tx_counties)
sf_counties <- st_transform(sf_counties, 4326)  # hard coding the CRS compatibility 

###this did not work, retrying 
#weather_merge <- over(filt_tx_weather, sf_counties)
#weather_merge <- sapply(st_intersects(sp_tx_df,sf_counties), function(z) if (length(z)==0) NA_integer_ else z[1])
#weather_recombined <- cbind(sp_tx_df, weather_merge)
#plot(weather_recombined)
#plot(weather_recombined$DAMAGE_PROPERTY_NUM)
```
```{r}
# Why does this not work? Overlay
plot(tx_counties_sf) # Â¥ay made a map of counties of texas 
par(new = T)
plot(sp_tx_df, col = "blue", add = T) # events
par(new = F)

par(mfrow = c(1, 2))
plot(tx_counties_sf, axes = TRUE)
plot(sp_tx_df, axes = TRUE)
#clearly not on the same projection
```

OVER Merge 
```{r}
# making spatial polygons files 
counties_sf <- get_urbn_map("counties", sf = TRUE)
counties_shape_file <- as_Spatial(counties_sf, IDs = counties_sf$county_fips)
#counties_shape_file <- as(counties_shape_file, "Spatial") # makes a SpatialPolygons object 
# Spatial Polygons DataFrame
tx_counties_sf <- subset(counties_shape_file, counties_shape_file$state_abbv == "TX")

# setting CRS 
proj4string(sp_tx_df) <- crs.geo
proj4string(tx_counties_sf) <- crs.geo

#tx_counties_sf <- CRS(proj4string(tx_counties_sf))
#tx_events_proj <- spTransform(sp_tx_df, tx_counties_sf)

```


trying to get the same CRS 
```{r}
# this is a spatial polygons dataframe 
head(tx_counties_sf)

# county map needs to be re-projected to be long/lat 
tx_counties_sf <- sp_transform(tx_counties_sf, sp_tx_df)
crs.geo <- CRS("+init=EPSG:4326")
proj4string(tx_counties_sf) <- crs.geo
is.projected(tx_counties_sf)
summary(tx_counties_sf)
```

```{r}
library(maptools)
#counting num of events in each county
###over.list <- over(tx_counties_sf, geometry(sp_tx_df), returnList = TRUE)
over.list <- over(geometry(sp_tx_df), tx_counties_sf, returnList = TRUE)
merged.weather <- spCbind(sp_tx_df, over.list)
num.events <- sapply(over.list, length)
counties <- spCbind(tx_counties_sf, num.events)

events_per_dist <- over(counties, merged.weather, returnList = FALSE)
events_per_dist[!is.na(events_per_dist)]

```


# Maybe if I used sf package instead? 
```{r}
# sf type counties data 
class(counties_sf)
plot(counties_sf)

ct_tx_sf <- counties_sf[counties_sf$state_abbv == 'TX',]

plot(ct_tx_sf)

sf_tx_df = st_as_sf(sp_tx_df) # this warning should be okay

#set CRS the same 
sf_tx_df <- st_set_crs(sf_tx_df, 2163)

# this join doesn't seem to work
joined <- st_join(sf_tx_df, ct_tx_sf)

# this doesn't work either 
intersects <- st_intersects(sf_tx_df, ct_tx_sf)

# doesn't work, can't merge over two sf objects
joined <- merge(sf_tx_df, ct_tx_sf, by.x= "CZ_FIPS", by.y="county_fips")

# checking if there's any overlap
any(st_touches(sf_tx_df, ct_tx_sf, sparse = FALSE))
# doesn't seem to be any 'touches'

# trying a non-overlaping join 
sf_tx_df_P = st_transform(sf_tx_df, 4326)
ct_tx_sf_P = st_transform(ct_tx_sf, 4326)

sel = st_is_within_distance(sf_tx_df_P, ct_tx_sf_P, dist = 20)
summary(lengths(sel) > 0) # this did not seem to work at all whatsoever 

```

# Stepping back 

I am really trying to take the weather data and the lat/long associated with it to then find the county_fips code. This should be a spatial join on the long/lat and then grabbing the county_fips and adding that to the tx_weather file. 

# trying again 
```{r}
# x=points, y=polygon
pts <- sf_tx_df_P$geometry
pol <- ct_tx_sf_P$geometry
joined <- st_contains(pts, pol)
mat = st_intersects(pts, pol, sparse = FALSE)
```

# Found the issue 
Even with CRS set to the same and etc, I am realizing that the coordinate values have the wrong PERIOD! Instead of being after the first two digits, the coordinate is after the first 6 digits! Why!!! Now I just need to Gsub and I should be back on track. 


```{r}
ct_tx_sf_mod <- ct_tx_sf
bad_cords <- as.data.frame(st_coordinates(ct_tx_sf))
bad_cords[1,"X"] 

bad_cords[1]
# these g subs are not right but they're what I have 
bad_cords$X <- as.numeric(gsub("([[:digit:]]{6,6})$", ".\\1", 
                      bad_cords$X)) 
bad_cords$Y <- as.numeric(gsub("([[:digit:]]{6,6})$", ".\\1", 
                      bad_cords$Y)) 
```

This might not be the issue -- ask Paulina tomorrow. 
